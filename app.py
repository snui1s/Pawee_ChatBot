import os
import psycopg2
from psycopg2 import pool
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, AIMessage, ToolMessage
from langchain_core.tools import tool
import gradio as gr

# Load environment variables
load_dotenv(override=True)

# --- DATABASE SETUP ---
DATABASE_URL = os.getenv("DATABASE_URL")
db_pool = None


def execute_query(query, params=None):
    """Utility function to execute a query using the connection pool."""
    if not db_pool:
        return
    conn = None
    try:
        conn = db_pool.getconn()
        with conn.cursor() as cur:
            cur.execute(query, params)
            conn.commit()
    except Exception as e:
        print(f"--- ERROR executing query: {e} ---")
    finally:
        if conn:
            db_pool.putconn(conn)


def init_db():
    """Initializes the database tables and ensures the schema is up to date."""
    print("--- SYSTEM: Verifying database schema... ---")

    # 1. Create unknown_questions table
    execute_query(
        """
        CREATE TABLE IF NOT EXISTS unknown_questions (
            id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            created_at TIMESTAMPTZ DEFAULT NOW(),
            question TEXT
        );
    """
    )

    # 2. Create user_leads table
    execute_query(
        """
        CREATE TABLE IF NOT EXISTS user_leads (
            id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
            created_at TIMESTAMPTZ DEFAULT NOW(),
            email TEXT
        );
    """
    )

    # 3. Ensure 'name' column exists in user_leads (Migration)
    execute_query(
        """
        DO $$ 
        BEGIN 
            IF NOT EXISTS (SELECT 1 FROM information_schema.columns WHERE table_name='user_leads' AND column_name='name') THEN
                ALTER TABLE user_leads ADD COLUMN name TEXT;
            END IF;
        END $$;
    """
    )
    print("--- SYSTEM: Database schema is up to date ---")


# --- INITIALIZE CONNECTION POOL ---
try:
    if DATABASE_URL:
        db_pool = psycopg2.pool.ThreadedConnectionPool(1, 10, DATABASE_URL)
        print("--- SYSTEM: Database Connection Pool initialized ---")
        init_db()
    else:
        print("--- WARNING: DATABASE_URL missing. Data will NOT be saved ---")
except Exception as e:
    print(f"--- ERROR: Could not initialize DB Pool: {e} ---")


# --- TOOLS ---
@tool
def record_unknown_question(question: str) -> str:
    """Record a question that you don't know the answer to, or is outside your professional context."""
    print(f"--- LOG: UNKNOWN QUESTION RECORDED: '{question}' ---")
    execute_query("INSERT INTO unknown_questions (question) VALUES (%s)", (question,))
    return f"Question '{question}' has been recorded for Pawee to review."


@tool
def record_user_details(email: str, name: str = None) -> str:
    """Record the user's contact details (email and optionally name) when they want to get in touch."""
    log_msg = f"'{email}'" if not name else f"'{name}' ({email})"
    print(f"--- LOG: USER DETAILS RECORDED: {log_msg} ---")
    execute_query("INSERT INTO user_leads (email, name) VALUES (%s, %s)", (email, name))
    return (
        f"Thank you! Your details have been recorded. Pawee will get back to you soon."
    )


# --- BOT LOGIC ---
class PaweeBot:
    def __init__(self):
        self.name = "Pawee Indulakshana"
        self.llm = ChatOpenAI(model="gpt-4o-mini", temperature=0.7)
        self.tools = {
            "record_unknown_question": record_unknown_question,
            "record_user_details": record_user_details,
        }
        self.llm_with_tools = self.llm.bind_tools(list(self.tools.values()))

        # Load summary
        summary_path = "me/summary.txt"
        self.summary_context = ""
        if os.path.exists(summary_path):
            with open(summary_path, "r", encoding="utf-8") as f:
                self.summary_context = f.read()

        self.system_prompt = (
            f"You are acting as {self.name}. You are answering questions on {self.name}'s website, "
            f"particularly questions related to {self.name}'s career, background, skills, and experience. "
            "Your responsibility is to represent him as faithfully as possible.\n\n"
            "Style: Professional and relaxed with a touch of playfulness, as if talking to a potential client or employer.\n\n"
            "Language Support: You are fluent in BOTH English and Thai. Always respond in the language the user is using.\n\n"
            "Guidelines:\n"
            "1. Use the provided Summary context to answer questions about Pawee's background.\n"
            "2. If a user asks a question about Pawee's personal life or professional details that are GENUINELY not in the summary, use the 'record_unknown_question' tool.\n"
            "3. DO NOT use the tool for general conversation, greetings, or questions about your own capabilities (like 'Can you speak Thai?'). Always answer those directly based on your character.\n"
            "4. If the user wants to connect, ask for their email and use the 'record_user_details' tool.\n\n"
            f"## Summary:\n{self.summary_context}\n"
        )

    def chat(self, message, history):
        messages = [SystemMessage(content=self.system_prompt)]

        # Sliding Window (Last 10 messages)
        context_window = history[-10:] if len(history) > 10 else history
        for msg in context_window:
            if msg["role"] == "user":
                messages.append(HumanMessage(content=msg["content"]))
            elif msg["role"] == "assistant":
                messages.append(AIMessage(content=msg["content"]))

        messages.append(HumanMessage(content=message))

        while True:
            response = self.llm_with_tools.invoke(messages)
            messages.append(response)

            if not response.tool_calls:
                break

            for tool_call in response.tool_calls:
                tool_name = tool_call["name"]
                tool_args = tool_call["args"]
                tool_func = self.tools[tool_name]

                result = tool_func.invoke(tool_args)
                messages.append(
                    ToolMessage(content=str(result), tool_call_id=tool_call["id"])
                )

        return response.content


from fastapi import FastAPI
import uvicorn

# --- INTERFACE ---
if __name__ == "__main__":
    bot = PaweeBot()

    theme = gr.themes.Soft(
        primary_hue="blue",
        secondary_hue="slate",
    )

    # 1. Create the Gradio interface
    demo = gr.ChatInterface(
        fn=bot.chat,
        title=f"Chat with {bot.name}",
        description=f"You can leave contact details (email, name) to get in touch. I will get back to you as soon as possible.",
        examples=[
            "Tell me about your AI experience",
            "เล่าประวัติของคุณให้ฟังหน่อย",
            "How can I contact you?",
        ],
    )

    # 2. Get the internal FastAPI app from Gradio
    app = demo.app

    # 3. Add Health Check & HEAD support to the ALREADY WORKING Gradio app
    @app.head("/")
    @app.get("/health")
    def health_check():
        return {"status": "ok"}

    # 4. Launch using uvicorn to respect Render's PORT
    port = int(os.environ.get("PORT", 7860))
    print(f"--- SYSTEM: Launching Server on port {port} ---")
    uvicorn.run(app, host="0.0.0.0", port=port)
